{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "import optuna\n",
    "import shap\n",
    "from sklearn.inspection import partial_dependence, PartialDependenceDisplay\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "X_train = pd.read_csv(r\"D:\\Train_60\\Train_60\\Train_60\\X_Train_Data_Input.csv\")\n",
    "Y_train = pd.read_csv(r\"D:\\Train_60\\Train_60\\Train_60\\Y_Train_Data_Target.csv\")\n",
    "X_test = pd.read_csv(r\"D:\\Test_20\\Test_20\\Test_20\\X_Test_Data_Input.csv\")\n",
    "Y_test = pd.read_csv(r\"D:\\Test_20\\Test_20\\Test_20\\Y_Test_Data_Target.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 'ID' column from both X_train and X_test\n",
    "X_train = X_train.drop(columns=['ID', 'target'])\n",
    "X_test = X_test.drop(columns=['ID'])\n",
    "Y_train = Y_train.drop(columns=['ID'])\n",
    "Y_test = Y_test.drop(columns=['ID'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing values\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "X_test_imputed = imputer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert back to DataFrame\n",
    "X_train_imputed = pd.DataFrame(X_train_imputed, columns=X_train.columns)\n",
    "X_test_imputed = pd.DataFrame(X_test_imputed, columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_imputed)\n",
    "X_test_scaled = scaler.transform(X_test_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert back to DataFrame\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     feature       VIF\n",
      "0    Column0  1.054533\n",
      "1    Column1  1.488827\n",
      "2    Column2  1.103574\n",
      "3    Column3  4.862719\n",
      "4    Column4  5.178206\n",
      "5    Column5  1.000114\n",
      "6    Column6  1.165029\n",
      "7    Column7  1.024339\n",
      "8    Column8  1.261413\n",
      "9    Column9  1.026054\n",
      "10  Column10  4.106833\n",
      "11  Column11  4.590756\n",
      "12  Column12  3.894457\n",
      "13  Column13  4.374858\n",
      "14  Column14  1.000211\n",
      "15  Column15  1.000613\n",
      "16  Column16  1.020774\n",
      "17  Column17  1.092544\n",
      "18  Column18  1.249391\n",
      "19  Column19  1.157325\n",
      "20  Column20  1.140316\n",
      "21  Column21  1.098497\n"
     ]
    }
   ],
   "source": [
    "# Calculate VIF\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"feature\"] = X_train_scaled.columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X_train_scaled.values, i) for i in range(X_train_scaled.shape[1])]\n",
    "print(vif_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     feature       VIF\n",
      "0    Column0  1.054531\n",
      "1    Column1  1.397204\n",
      "2    Column2  1.102766\n",
      "3    Column3  1.099390\n",
      "4    Column5  1.000113\n",
      "5    Column6  1.164084\n",
      "6    Column7  1.024330\n",
      "7    Column8  1.260642\n",
      "8    Column9  1.026039\n",
      "9   Column10  4.106157\n",
      "10  Column11  4.590508\n",
      "11  Column12  3.889872\n",
      "12  Column13  4.373771\n",
      "13  Column14  1.000211\n",
      "14  Column15  1.000597\n",
      "15  Column16  1.020620\n",
      "16  Column17  1.091214\n",
      "17  Column18  1.242985\n",
      "18  Column19  1.157106\n",
      "19  Column20  1.139414\n",
      "20  Column21  1.098446\n"
     ]
    }
   ],
   "source": [
    "# Drop Column4 due to high VIF\n",
    "columns_to_drop = ['Column4']\n",
    "\n",
    "X_train_reduced = X_train_scaled.drop(columns=columns_to_drop, axis=1)\n",
    "X_test_reduced = X_test_scaled.drop(columns=columns_to_drop, axis=1)\n",
    "\n",
    "# Recompute VIF after dropping the column to verify if it reduces multicollinearity\n",
    "vif_data_reduced = pd.DataFrame()\n",
    "vif_data_reduced[\"feature\"] = X_train_reduced.columns\n",
    "vif_data_reduced[\"VIF\"] = [variance_inflation_factor(X_train_reduced.values, i) for i in range(X_train_reduced.shape[1])]\n",
    "print(vif_data_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_train_reduced, X_val, Y_train, Y_val = train_test_split(X_train_reduced, Y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-11 15:47:08,642] A new study created in memory with name: no-name-73ba9d1f-50d5-4fcc-ab35-701b86ba3ed5\n",
      "[I 2024-10-11 15:50:34,281] Trial 0 finished with value: 0.9765135187684205 and parameters: {'n_estimators': 171, 'max_depth': 15, 'min_samples_split': 6, 'min_samples_leaf': 4, 'max_features': 'sqrt'}. Best is trial 0 with value: 0.9765135187684205.\n",
      "[I 2024-10-11 15:52:53,081] Trial 1 finished with value: 0.976895619637947 and parameters: {'n_estimators': 117, 'max_depth': 20, 'min_samples_split': 9, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 1 with value: 0.976895619637947.\n"
     ]
    }
   ],
   "source": [
    "# Optuna for hyperparameter tuning\n",
    "def objective(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 100, 200)\n",
    "    max_depth = trial.suggest_int('max_depth', 10, 30)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 10)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 5)\n",
    "    max_features = trial.suggest_categorical('max_features', ['sqrt', 'log2', None])\n",
    "\n",
    "    rf_model = RandomForestClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        max_features=max_features\n",
    "    )\n",
    "    \n",
    "    return cross_val_score(rf_model, X_train_reduced, Y_train, cv=5, n_jobs=-1).mean()\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=5) \n",
    "\n",
    "best_params = study.best_params\n",
    "final_rf_model = RandomForestClassifier(**best_params, random_state=42)\n",
    "final_rf_model.fit(X_train_reduced, Y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_val_pred = final_rf_model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "accuracy = accuracy_score(Y_val, y_val_pred)\n",
    "conf_matrix = confusion_matrix(Y_val, y_val_pred)\n",
    "class_report = classification_report(Y_val, y_val_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation scores\n",
    "cv_scores = cross_val_score(final_rf_model, X_train_reduced, Y_train, cv=5)\n",
    "print(\"Cross-Validation Scores:\", cv_scores)\n",
    "print(\"Mean CV Accuracy:\", cv_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC-AUC score\n",
    "y_proba = final_rf_model.predict_proba(X_val)[:, 1]\n",
    "roc_auc = roc_auc_score(Y_val, y_proba)\n",
    "print(f\"ROC-AUC Score: {roc_auc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve visualization\n",
    "fpr, tpr, _ = roc_curve(Y_val, y_proba)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=\"ROC Curve\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature interactions or polynomial features\n",
    "poly = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n",
    "X_train_poly = poly.fit_transform(X_train_scaled)\n",
    "X_test_poly = poly.transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA for dimensionality reduction\n",
    "pca = PCA(n_components=0.95)  # Retain 95% of variance\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP values for feature importance analysis\n",
    "explainer = shap.Explainer(final_rf_model, X_train_reduced)\n",
    "shap_values = explainer(X_val)\n",
    "shap.summary_plot(shap_values, X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partial Dependence Plot (PDP)\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "PartialDependenceDisplay.from_estimator(final_rf_model, X_train_reduced, [0, 1], ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline creation\n",
    "pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', RandomForestClassifier(**best_params, random_state=42))\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, Y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "joblib.dump(final_rf_model, 'final_rf_model.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
